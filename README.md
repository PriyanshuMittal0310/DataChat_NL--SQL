ğŸ“˜ DataChat â€“ Natural Language to SQL with RAG (Supabase + Groq + Ollama + Next.js)

DataChat is an AI-powered data analytics system that allows users to:

1.Upload one CSV dataset

2.Automatically load it into Supabase Postgres

3.Ask questions in natural language

4.Convert the questions to SQL using Groq LLM

5.Automatically execute SQL on Supabase

6.Display results in tables and charts

7.Speed up repeated/related questions using a pgvector-based RAG semantic cache

This project integrates Next.js App Router, Supabase, Groq LLM, Ollama embeddings, and pgvector to create a complete NL â†’ SQL â†’ Analytics pipeline.

ğŸ‘¥ Team Members
Name	          Roll No.	      Contribution
PIYUSH PRASHANT	  24BDS055	       RAG pipeline, embeddings
MS HARSHITHA	  24BDS038	       Testing, documentation, integration
PRIYANSHU MITTAL  24BDS058	       Backend, Supabase integration, Visualisation
JAKKUVA SAMEER    24BDS026         Frontend UI,Debugging

Replace placeholders with your actual details before submission.

ğŸ“ Repository Structure
DATACHAT_NL--SQL-MAIN/
â”‚
â”œâ”€â”€ app/                     # Next.js App Router
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chat/            # Main NL â†’ SQL chat route
â”‚   â”‚   â”œâ”€â”€ upload-csv/      # Converts CSV â†’ Supabase table
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”œâ”€â”€ page.tsx
â”‚   â””â”€â”€ globals.css
â”‚
â”œâ”€â”€ components/              # All UI components
â”‚   â”œâ”€â”€ chat-interface.tsx
â”‚   â”œâ”€â”€ chat-message.tsx
â”‚   â”œâ”€â”€ results-table.tsx
â”‚   â”œâ”€â”€ data-chart.tsx
â”‚   â”œâ”€â”€ csv-upload.tsx
â”‚   â””â”€â”€ ui/
â”‚
â”œâ”€â”€ lib/                     # Backend utilities & RAG implementation
â”‚   â”œâ”€â”€ setup.ts             # Auto-create pgvector, memory, cache tables
â”‚   â”œâ”€â”€ embeddings.ts        # Embeddings using Ollama (nomic-embed-text)
â”‚   â”œâ”€â”€ query-cache.ts       # pgvector search + storage
â”‚   â”œâ”€â”€ query-executor.ts    # Executes SQL on Supabase
â”‚   â”œâ”€â”€ db.ts                # Loads schema dynamically
â”‚   â”œâ”€â”€ memory.ts            # Conversation memory storage
â”‚   â”œâ”€â”€ session.ts           # Session ID generator
â”‚   â”œâ”€â”€ prompts.ts           # System prompt
â”‚   â”œâ”€â”€ sql-validator.ts     # SQL safety validator
â”‚   â””â”€â”€ types.ts
â”‚
â”œâ”€â”€ scripts/                 # SQL DDL scripts (optional manual use)
â”‚   â”œâ”€â”€ 01-setup-database-functions.sql
â”‚   â”œâ”€â”€ 02-reload-schema-cache.sql
â”‚   â”œâ”€â”€ 03-conversation-memory.sql
â”‚   â””â”€â”€ conversation-query-cache.sql
â”‚
â”œâ”€â”€ public/
â”œâ”€â”€ styles/
â”‚
â”œâ”€â”€ .env.local               # Environment variables
â”œâ”€â”€ env.example
â”œâ”€â”€ DEPLOYMENT.md
â”œâ”€â”€ COMPLETE-PROJECT-SUMMARY.md
â”œâ”€â”€ package.json
â””â”€â”€ README.md

âš™ï¸ Installation & Setup Guide
1ï¸âƒ£ Prerequisites

Make sure you have:

Node.js 18+

npm or pnpm

Supabase project (URL + keys)

Groq API key

Ollama installed locally

nomic-embed-text embedding model

2ï¸âƒ£ Clone the Repository
git clone <repo-url>
cd DATACHAT_NL--SQL-MAIN

3ï¸âƒ£ Install Dependencies
npm install


or

pnpm install

4ï¸âƒ£ Setup Environment Variables

Create .env.local in the root:

# Supabase
NEXT_PUBLIC_SUPABASE_URL=https://<your-project>.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=<anon-key>
SUPABASE_SERVICE_ROLE_KEY=<service-role-key>

# Groq API
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxxx

# Embeddings
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_DIM=768

5ï¸âƒ£ Install & Run Ollama
Install Ollama:

Windows:

winget install Ollama.Ollama


Mac:

brew install ollama


Linux:

curl -fsSL https://ollama.com/install.sh | sh

Pull the embedding model:
ollama pull nomic-embed-text

Start Ollama:
ollama serve

6ï¸âƒ£ Start Dev Server
npm run dev


Open:
ğŸ‘‰ http://localhost:3000

ğŸ” How the System Works
â–¶ï¸ Step 1 â€” Upload CSV

You upload one CSV file

The system parses and converts it into a Supabase table:

session_<sessionId>_<fileName>

â–¶ï¸ Step 2 â€” Ask a Natural Language Question

Example:
"Show me the total records"

â–¶ï¸ Step 3 â€” Embedding + RAG Search

Your question is embedded using nomic-embed-text (768-dim)

RAG searches conversation_query_cache using pgvector

If similarity > threshold â†’ cache hit

Else â†’ generate SQL with Groq

â–¶ï¸ Step 4 â€” SQL Generation (Groq LLM)

Groqâ€™s fast models generate:

SQL query

Explanation summary

â–¶ï¸ Step 5 â€” SQL Execution

SQL validated

Run on Supabase using RPC

Result returned in JSON

â–¶ï¸ Step 6 â€” Output Rendering

Table view

Chart view (Recharts: bar, line, stacked bar)

Summary in natural language

â–¶ï¸ Step 7 â€” Store in Query Cache

Saved into:

Column	Purpose
question	natural question
normalized_sql	stored SQL
result_sample	1â€“100 rows
row_count	total
question_embedding	768-vector
session_id, table_name	contextual info
â–¶ï¸ Execution Summary
Action	Command
Install deps	npm install
Start Ollama	ollama serve
Run dev server	npm run dev
Open app	http://localhost:3000


ğŸ¥  Demo Video (Required for Submission)

Google drive link:

ğŸ‘‰ https://drive.google.com/file/d/1sse8FFnlriYNVltsP1hpq3QQq2qXtd3b/view?usp=sharing

Suggested Script:

Start app

Upload CSV

Ask a question

Show SQL generated

Show result table

Open chart

Ask similar question

Demonstrate RAG cache hit

Summarize features